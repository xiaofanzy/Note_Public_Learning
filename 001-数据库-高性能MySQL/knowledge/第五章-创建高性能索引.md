# 第五章 创建高性能的索引

## 01 索引基础

MySQL 先按照索引上按值进行搜索，然后返回包含该值的数据行；

MySQL 只能高效的使用索引的最左前缀列；

### 001 索引类型

#### B-Tree

Archive 引擎原不支持任何索引，直到 5.1 支持 auto_increment 索引；

MyISAM 采用采用前缀压缩使得索引更小，InnoDB 按照原数据格式进行存储；MyISAM 通过数据的物理位置引用被索引的行，InnoDB 根据主键引用被索引的行；

![image](images/XCR5mambf4_edW-NrXc7DYEO8jvxpMGaVZZ7re4jgcY.png)

从索引的根节点进行搜索，根节点的槽中存放了指向子节点的指针，存储引擎根据这些指针往下遍历搜索，通过节点页中的值和需要查找的值匹配从而判断是否需要往下查找，是否需要进入到下层子节点，最终存储引擎要么找到该值，要不不存在该值；

叶子结点比较特别，指针指向了被索引的数据，而不是其他的节点页；树的深度和表的大小有关；

B-Tree 树按照顺序存储的，所以很适合查找类似从 A-K 的这种范围类型的数据；

**B-Tree 树匹配逻辑：**

1. 全值匹配；匹配 Cube Allen 1960-01-01 的人
2. 匹配最左前缀 匹配所有 Allen 的人；
3. 匹配列前缀 匹配某一列的开头 比如 J 开头的人
4. 匹配范围值 匹配索引第一列 比如查找 Allen 到 Barry 之间的人
5. 精确匹配某一列并范围匹配另外一列 精确匹配姓 Allen 的人，模糊匹配 first_name 是 K 开头的人；
6. 只访问索引的查询； 只访问索引的查询，覆盖索引；

B 树既然在树节点中是有序的，所以我们也可以通过索引来进行 order by 排序操作；

b-tree 索引可以适用于全职建、键值范围、键前缀；

**B-Tree 树限制：**

1. 如果不是按照索引的最左列进行查找，则无法使用索引；这里的最左列是 last_name,如果最左列不是这个，则无法使用索引；

![image](file://C:\Users%E5%87%A1%E6%98%AF%E5%85%AD%E4%B8%80\AppData\Roaming\Typora\typora-user-images\image-20230216092855218.png?lastModify=1692092896)

2. 不能跳过被索引中的列；如果查询 last_name = smith dob = 1960-01-01 的人，就跳过了 first_name，这就无法使用索引了；
3. 如果查询某个列的范围查询，则其右边所有列都无法使用索引优化查找；范围查询之后的列无法使用索引优化；

```Plain Text
# 这种情况，只能使用索引中的last_name,first_name这两个索引，而无法使用job索引，因为fist_name是范围索引，他之后的条件需要进行全表扫描，建议如果fist_name不多的话，可以使用多个匹配条件的方式；
where last_name = 'Smith' and fisrt_name like '%J%' and dob = '1960-01-01';
```

#### 哈希索引

哈希索引基于哈希表实现，只有精确匹配所有列查询才有效；对于每一行数据，存储引擎会计算出一个哈希码，然后存储在索引中，哈希表中存储了指向数据行的指针；

Memory 引擎支持哈希索引，他同样支持 b 树索引。如果多个列的哈希值相同，索引会以链表的方式存放多个记录指针到同一个哈希条目中；

哈希表因为结构紧凑，速度非常快；

```sql
## 创建表结构，使用hash索引
create table testhash(
    fname varchar(50) not null,
    lname varchar(50) not null,
    key using hash(fname)
)engline  = memroy;
```

![image](file://C:\Users%E5%87%A1%E6%98%AF%E5%85%AD%E4%B8%80\AppData\Roaming\Typora\typora-user-images\image-20230216094248615.png?lastModify=1692092896)

```Plain Text
## 查询数据；
## 查询逻辑；先计算Peter的哈希值，然后根据该值查询到记录指针，然后根据记录指针在哈希条目中查到第几行存储了该数据，然后比较数据值是否匹配；确保无误；
select * from testhash where lname = 'Peter';
```

**哈希索引的限制：**

1. 哈希索引只包含哈希值和行指针，不存储字段值，所以不能使用索引中的值来避免读取行；不过因为哈希索引行速度快，所以对性能影响不大；
2. 哈希索引无法进行排序，因为不是按照顺序存储的；
3. 哈希索引不支持列匹配查找，因为哈希索引使用的是列的全部内容，而不是列的部分内容；（a,b）建立哈希索引，那只有数据 A 的情况下，无法使用索引；
4. 哈希索引只支持等值比较查询，支持 = in() <=> 但是不支持范围查询 >, < 等
5. 访问哈希索引的数据非常快，除非有很多哈希冲突（不同的数据列有同一个哈希值）当出现哈希冲突的时候，存储引擎需要遍历所有指针，逐行比较，知道找到所有复合条件的行；
6. 哈希冲突过多也会导致维护操作的代价很高，冲突越多，代价越大，比如在 sex 这一列上建立 hash 索引，那么冲突就非常多，那么当删除一行数据的时候，就需要遍历所有数据，找到删除的行对应的引用。

InnoDB 中也有一个自适应的哈希索引，这是一个完全自动的内部行为，他会对使用非常频繁的索引值在 b 树上在创建一个 hash 索引，让索引可以更加快速；

##### 创建自定哈希索引

思路就是使用 B 树进行索引查找，但是使用哈希值而不是键本身，我们制定这个 hash 值作为索引即可；就是可以使用伪哈希索引了；

```Plain Text
#建一个表，将url作为索引列
mysql> create table pseudohash (
    -> id int unsigned NOT NULL auto_increment,
    -> url varchar(255) NOT NULL,
    -> url_crc int unsigned NOT NULL DEFAULT 0,
    -> PRIMARY KEY(id)
    -> );
​
​
## 未优化之前；
select id from pseudohash where url = 'Http://wwww.baidu.com';
​
## 优化之后， 我们建立一个url_crc列，这个列使用crc32作为哈希值；
## 就是我们新增一个列，这个列存储的是hash表，然后呢，我们使用这个列去查找，那么就相当于使用hash去查找，而这个列的存储，我们可以通过触发器来触发，当insert或者update的时候，我们修改该列的url_crc列的值，然后使用url 和url_crc列的数据，两个卡一个查询，这样就类似使用了hash索引的方式，查找数据；
​
## 但是不要使用sha1() 和 MD5作为哈希函数，这两个函数使用的哈希值非常长，会浪费大量空间，同事也比较慢；sha1() 和 MD5是强加密函数，这里不需要；
​
#改变一下语句执行的分隔符
mysql> DELIMITER //
#创建触发器
## 当新增的时候，修改url_crc列的数据
mysql> CREATE TRIGGER pseudohash_crc_ins BEFORE INSERT ON pseudohash FOR EACH ROW BEGIN
    -> SET NEW.url_crc=crc32(NEW.url);
    -> END;
    -> //
## 当修改的时候，修改url_crc列的数据
mysql> CREATE TRIGGER pseudohash BEFORE UPDATE ON pseudohash FOR EACH ROW BEGIN
    -> SET NEW.url_crc=crc32(NEW.url);
    -> END;
    -> //
#改为原来的分隔符
mysql> DELIMITER ;
​
# 查询；
## 为了避免哈希冲突，所以我们必须代入哈希值和对应的列值，如果只统计记录数，则直接使用crc32()即可
mysql> SELECT * FROM pseudohash WHERE url="http://www.mysql.com/"
    -> AND url_crc=CRC32("http://www.mysql.com/");
​
```

当如果存在大量 hash 冲突的时候，我们可以自定义一个哈希算法，实现简单，但是比自己写一个 hash 算法性能要差，建议这么干；

hash 冲突比实际要快，差不多 10 万条数据，就有 1%的哈希冲突，所以我们可以自定义一个 64 位 hash 索引；

```Plain Text
SELECT CONV(RIGHT(MD5('http://www.baidu.com/'),16),16,10) as hash64;
```

#### 空间数据索引 R-Tree

无需前缀查询，空间索引会从所有纬度来索引数据，查询的时候，可以使用任意维度来组合查询，但是好多人不用，因为 mysql 对这个支持不完善；

#### 全文索引

🌮 全文索引适用于 match against 操作，而不是简单的 where 条件操作；

## 02 索引的优点

B-Tree 索引按照顺序排序的方式，可以作为 order by 和 group by 操作，数据有序的，所以 b-tree 将相关的列值存储在一起；

#### 001 优点：

1. 索引减少了服务器需要扫描的数据量
2. 索引可以帮助服务器避免排序和临时表；
3. 索引可以将随机 I/O 改为顺序 I/O

元数据信息表代替索引，这个是对于 TB 类型的数据常用的操作；

## 03 高性能索引策略

### 001 独立的列

独立的列是指索引列不能是表达式的一部分，也不能是函数的参数；

```Plain Text
# 这种情况无法使用索引，我们需要将索引作为单独的条件放在比较符号的一侧；
select actor_id from sakila.actor where actor_id + 1 = 5;
​
## 修改为
select actor_id from sakila.actor where actor_id  = 4;
```

### 002 前缀索引和索引选择性

索引很长序列的时候，除了哈希索引的方法，我们还可以使用前缀索引的方式，索引开始的部分字符，这样可以节约空间，提高索引效率，但是命中率会降低；

索引选择性：不重复的索引值(Selectivity)和数据表的记录总数（#T）的比值 1/#T 到 1 之间；索引选择性越高，则查询效率越高；

```Plain Text
Index Selectivity = Cardinality / #T
```

**列前缀的索引选择性足够高，可以满足查询性能，对于 BLOB TEXT 或者很长的 VARCHAR 列，必须使用前缀索引；**

足够长的前缀保持命中率，同时不能太长以节约空间；前缀的基数（就是索引值）应该接近于完整列的基数；

**当索引选择性在完整值的时候差不多可以认为选择性合适了；**

说到这里有个问题 ，count(1) 和 count(\*) 那个执行效率更高？

![image](images/Ly-IVazALr2w2cGWgTSipj0qe_4qbid_y9WRd-ocn_k.png)

```sql
# 我们先查找完整列的选择性；为0.4400 ，那么最接近0.4400比率的就是最合适的索引选择性；
mysql> select count(distinct city) / count(*) from city_demo;
+---------------------------------+
| count(distinct city) / count(*) |
+---------------------------------+
|                          0.4400 |
+---------------------------------+
1 row in set (0.00 sec)
​
​
## 可以看到，长度为6的时候，最接近这个数；那么我们就选取长度为6作为前缀索引；
mysql> select count(distinct left(city,4))/count(*) as a1,
    -> count(distinct left(city,5))/count(*) as a2,
    -> count(distinct left(city,6))/count(*) as a3
    -> from city_demo;
+--------+--------+--------+
| a1     | a2     | a3     |
+--------+--------+--------+
| 0.4183 | 0.4308 | 0.4367 |
+--------+--------+--------+
1 row in set (0.00 sec)
​
## 创建索引；
alter table city_demo add key (city(6));
```

**缺点：**

1. 无法作为 order by 和 group by;
2. 也无法使用前缀索引做覆盖扫描；

当然也可以使用后缀索引，不过后缀索引是通过后缀索引然后翻转的形式的，因为 MySQL 没有后缀索引的查找方式，我们就用这种讨巧的方式；类似于前面的**创建自定义 hash 索引**的方式；

### 003 多列索引

单列索引的方式，MySQL 后面会使用索引合并的方式，但是不建议每个列都进行单列索引，这样的索引策略很烂；

- 当服务器对多个索引进行相交操作的时候，就是 and 条件的情况下，意味着需要一个**包含所有相关列的多列索引**，而不是多个独立的单列索引；
- 当服务器对多个索引进行联合操作的时候 就是 or 条件的情况下，通过需要耗费大量 CPU 和内存资源在算法的缓存、排序、合并操作上，当索引选择性不高的情况，就需要合并扫描返回大量数据；
- 优化器不会把这些作为查询成本，优化器只关心随机页面读取，这样查询的成本被低估，导致甚至于比全表扫描都差，还可能影响查询的并发性，但是如果单独运行往往会忽略对并发性的影响，所以还不如用 UNION ALL 去拼 or 的操作；

如果查询到这个，那么需要看下索引是不是需要进行优化操作；

### 004 选择合适的索引列顺序

在 B-Tree 索引中，索引列的顺序，意味着按照最左列进行排序的，可以进行 order by ,group by distinct 等操作；

经验：将随机性高的列放到索引的最前列，比如 sex 和 photonumber 当 sex 的选择性高的时候也就是当通过 sex 判断比 photonumber 更容易判断出来那个是我们需要的数据的时候，比如 sex 的总数是 2 photonumber 总数是 200，我们使用 key(sex,photonumber) 替换 key(photonumer,sex);

经验 2：当决定全局基数和选择性的时候，我们可以通过查询索引选择性来判断索引顺序

```Plain Text
select count(distinct city)/count(*) as a1,
        count(distinct name)/count(*) as a2
         from dual;
判断那个的选择性更高，值越大的选择性越高；
```

🍎 实例

当查询非常慢的时候；

```Plain Text
## 查询非常慢；
select count(distinct threadId) as count_value
from message
where (groupId = 10137 ) and (usrId = 1288826) and (annonymous = 0)
order by prioroty desc,modifiedDate desc;
```

第一步，我们查看是否有合适索引：

![image](images/sEXx2Ewm-GM80V-qJN_ZO8XXcjmHv3sGj6l9NXS6Nos.png)

发现 key = id_groupId_userid 走了索引；

然后我们查询一下 userId 和 groupId 匹配的行数，就发现，命中率非常高；所以这个索引就无效了；

![image](images/S-dlxP6CownNAfOQ52nHf9uvuP3xC5-9lhtorScMjjk.png)

### 005 聚簇索引

聚簇索引，数据行和相邻的键值存储在一起，因为无法将数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引；

InnoDB 通过主键聚集数据，也就是被索引的列就是主键列，如果没有定义主键，那么就回选择一个唯一的非空索引代替，如果没有这样的索引，那么就会隐式的定义一个主键来作为聚簇索引的主键列；

InnoDB 可能对性能有帮助，但是也可能导致严重的性能问题，所以这个需要看实际需要；

叶子存放了行的全部数据，而节点页（二级索引）只包含的索引列

![image](images/Nwku_l-Ra_YJYmDltzUf8BFzled8kNB2DC7ISG0zAKY.png)

#### 优点：

1. 可以把相关数据放到一起；例如通过 ID 查询用户全部邮件，那么聚簇索引走的磁盘 IO 就很少；否每封邮件都会导致一次磁盘 IO
2. 数据访问更快，聚簇索引将索引和数据放到一个 B 数上，因此从索引中拿出具，肯定比非聚簇索引块；
3. 使用覆盖扫描的时候，查询可以直接使用叶子结点中的主键值；

#### 缺点

1. 聚簇索引最大程度提高了 I/O 密集型应用的性能，但是数据全部放到内存中，访问顺序就没那么重要了，那么聚簇索引的优势也就不存在了；
2. 插入速度严重依赖于插入顺序，按照主键插入是最快的方式，但是如果不是按照主键，最好通过 optimize table 重新组织一下表
3. 更新聚簇索引的代价很高，会强制 InnoDB 将每个更新的行移动到新的位置；
4. 页分裂的问题；占用更多的磁盘空间，当插入改行或者主键移动需要移动行的时候，行的主键值要求将这一列插入到已满页中的时候，存储引擎就回强制将其分为两个页面容纳进行，这就是一次页分裂的操作；
5. 全表扫描更慢，当行比较稀疏或者页分裂导致存储不连续的时候更为严重；
6. 二级索引（非聚簇索引）可能会很大， 因为二级索引的叶子结点包含了引用行主键列；
7. 二级索引查找需要两次索引查找，而非一次；他主要是二级节点保存的行指针实际上是行的主键值，这就意味着，我首先第一次会通过这个值查找到对应的主键列，然后我在来一次聚簇索引查找，然后通过主键列查找到具体的行；

#### InnoDb 和 MyISAM 的数据分部对比

🍎MyISAM

索引在创建主键列和非主键列的时候，本质上没有区别，只不过一个是主键列，一个是非主键列罢了；

当创建下面这个表，这个表有两个列，col1 作为主键列，而 col2 作为非主键列的时候；

```Plain Text
CREATE TABLE test (col1 int NOT NULL,
     col2 int NOT NULL,
     PRIMARY KEY(col1),
     KEY(col2));
```

我们随机生成 10000 条数据，数据表格如下：

![image](images/YLPujTP69Zp_di8Bj2zPPDu7xecJBK0CKcmctNtGTgQ.png)

MyISAM 索引主键列的时候，分部方式如下：

![image](images/y_ZJQmGpFUdJmSIFX4MuVMA-jyVA2-AcevjByqDJ3Rk.png)

我们通过叶子结点，查到所对应的行号，然后通过行号快速锁定具体行数；

而非主键列的时候，本质上没有什么区别，就是主键列不能为空；

![image](file://C:\Users%E5%87%A1%E6%98%AF%E5%85%AD%E4%B8%80\AppData\Roaming\Typora\typora-user-images\image-20230216134133237.png?lastModify=1692092896)

🎈 InnoDB 数据分布：

当 InnoDB 用聚簇索引的时候，他的叶子结点，带的数据太多了，包括主键值 col1，事务 idTID，回滚指针 RP 和剩余列 col2；好像 CF 里面带了六个背包一样；

![image](images/mzgt34g4RkXiPUHMGQCf6ZU8Hx7qdctIdczvD7mOCMU.png)

而二级节点中，存储的是行指针本质上其实是纸箱主键的主键值，这种策略减少了移动或者数据分页的时候二级索引的维护工作，但是会占用更多的空间，而且需要两次查询才能查询到数据；

![image](images/byXSvrYUkrMq2vkqfnO8oL7fmslq7woTYtEdCbhlSV4.png)

🦅 区别；

![image](images/zF9GPYd_mMumE8BCJjvjMN0aZ3a673lKTBq3XOjQwJo.png)

#### 在 InnoDB 中按主键顺序插入行；

如果没有数据聚集，我们可以使用一个自增的 auto_increment 自增列作为主键，这样保证数据行是按顺序插入的；

我们通过 UUID 插入行，花费的时间更长，一方面是主键字段长，另外一方方面是页分裂和碎片导致的；

通过随机 UUid

最好避免随机的聚簇索引，因为数据将没有任何聚集特性；

![image](file://C:\Users%E5%87%A1%E6%98%AF%E5%85%AD%E4%B8%80\AppData\Roaming\Typora\typora-user-images\image-20230216135321507.png?lastModify=1692092896)

具体差异如下：

![image](images/h2EZ5PpCcmDDVEY8LjxMEW8c5i0USwskNe1TLu0Msr8.png)

1. auto_increment 自增的时候，主键值是顺序的，所以每一次插入都会存储在上一条后面，当达到页的最大填充因子（15/16，留出部分空间用于以后修改）下一条记录就会被写入新的页中；这种方式，就是按照顺序加载的；查找也更方便；
2. 如果 uuid 这种方式，当插入一条数据的时候，主键不一定比之前插入的大，当主键比之前插入的小的时候，InnoDB 会为这一行寻找最合适的位置，那么就会在已有数据之间插入这条记录，那么就可能导致页分裂和优化等额外工作；AB 质检插入了一条 C -> A C B 这种方式；
3. 写入的目标页可能已经从磁盘或者缓存中移除，或者还没有加载到缓存中，所以 InnoDB 插入前不得不从磁盘中读取目标页到内存中，这会导致大量的随机 IO 产生；
4. 写入是乱序的，所以 InnoDB 需要做页分裂操作，以便为行分配空间，页分裂会导致大量的数据被移动，插入一次最少要修改三个页面而不是一个页；
5. 被写满读取的页由于被打乱，可能需要重新读取缓存；
6. 顺序主键在高并发的时候，并发插入会导致锁竞争；

**使用 InnoDB 应该尽可能的按照逐渐顺序插入数据，并且京可能的使用单调递增的聚簇键来插入新行；**

![image](images/eCGUOigtR_-YBPIQ-beMbEII8PDx9mHolFusfnn7YGA.png)

#### 介绍一下 AUTO_INCREMENT 锁机制；

自增锁，以方便是间隙锁影响性能，另一方面就是 AUTO_INCERMENT 锁机制会影响性能；

怎么处理：

**innodb_autoinc_lock_mode 配置可以控制在向 auto_increment 列表插入数据时相关锁的行为以及主从数据一致性的平衡**

> 术语：

> - simple inserts 预先知道插入行数的语句；
> - buik inserts 不能预先知道插入行数的语句；
> - mixed-mode inserts 混合插入；

> 类似于 INSERT INTO t1 (c1,c2) VALUES (1,'a'), (NULL,'b'), (5,'c'), (NULL,'d');

> - insert-like 所有插入语句的统称；

auto_increment 的锁定机制是通过 innodb_autoinc_lock_mode 参数来设置的，0、1、2，分别为 “traditional”, “consecutive”, or “interleaved”模式： “传统”、 “连续”或 “交错”锁定模式。

1. innodb_autoinc_lock_mode = 0 传统模式：

这种锁定模式，insert like 语句会获得一个特殊的 auto-inc 的自增表级锁，用于插入到所有自增的 auto_crement 列中，这个表级锁通常会保持到语句执行结束，而非事务结尾；目的就是为当前 insert 语句序列和可预约可重复的顺序分配自动增量值，并确保自动增量值的连续性；

副本服务器上，如果是单线程的，副本服务器上的值与源服务器上的值相同。副本复制源上相同的数据，当多线程执行的时候，ISNERT 语句被交错执行，则副本服务器上数据和源上的数据是不确定的；

```sql
CREATE TABLE t1 (
  c1 INT(11) NOT NULL AUTO_INCREMENT,
  c2 VARCHAR(10) DEFAULT NULL,
  PRIMARY KEY (c1)
) ENGINE=InnoDB;

Tx1: INSERT INTO t1 (c2) SELECT 1000 rows from another table ...
Tx2: INSERT INTO t1 (c2) VALUES ('xxx');
```

TX1 使用表级锁，一直锁定到 tx1 语句结束，每次执行一条，一直到 tx1 执行结束，才释放该表级锁；当 tx1 和 tx2 并行执行的时候，tx2 的自增值是大于 tx1 的自增还是小于，取决于哪个语句先执行；也就是 tx1 先执行，tx2 就会是 1001，而当 tx2 先执行的时候，则 tx1 的第一条记录就是 02 因为 01 被 tx2 占用了；这种情况下语句是串行执行的；

- **由于表级锁的限制，限制了并发性和可伸缩性；**

2. innodb_autoinc_lock_mode = 1 连续模式；

对于 simple insets 而言，他会预先在初始阶段将一条语句所需要的自增值一次性分配出来，通过一个互斥量保证序列的一致性，这个互斥量被确定之后，自增值生成完毕，就回释放这个互斥量，让其他语句执行；

对于 buik inserts 而言，他会箱传统模式一样，持有表锁一直到语句执行完毕释放该表锁；当 simple insets 和 buik inserts 一起执行的时候，buik inserts 正在执行的情况下，也不喜欢等到表锁释放才能执行 simple inserts;

- 并发性有所提高；

3. innodb_autoinc_lock_mode = 2 混合模式；

这种模式是 mysql8 之后使用的默认值，因为他默认的主从复制方式从 statement-based 改为了 row based 方式，row-based 方法解决了主从不一致的问题；

对于所有的 insert-like 语句，都不会存在 auto_inc 的这种表级锁，当同一张表多个语句并发执行的时候阻塞会大幅减少；每个语句执行的时候自增值的大小取决于谁竞争到互斥量，谁才有获得生成自增值的权利；

- 注意点：
- 自增值不能回滚，如果回滚，自增值会产生断裂；
- 正常情况下，自增值不存在 0 的，如果非要插入，就必须设置 NO_AUTO_VALUE_ON_ZERO；
- 修改；

```Plain Text
ALTER TABLE ...AUTO_INCERMENT = 1;
```

### 006 覆盖索引

如果一个索引包含了所有需要查询的字段的值，这种就叫做覆盖索引；

#### 优点：

1. 索引条目远小于数据行大小，所以只需要读取索引，MySQL 就会极大地减少数据访问量，这对缓存的负载非常重要，覆盖索引对于密集型引用也很有帮助，索引可以全部放入内存中；MyISAM 能够压缩索引以变的很小；
2. 索引在单页中按照列值顺序存储的，对于 I/O 密集型范围查询，顺序查询比随机 I/O 要少得多，对于 MyISAM 和 percona XtreaDb，可以通过 OPTIMIZE 命令完全顺序排列；
3. 一些存储引擎在内存中只缓存索引，数据依赖操作系统来缓存，如 MyISAM，因此访问数据需要一次一次系统调用；这全部索引的数据会导致性能严重受影响；
4. 对于 InnoDB 的聚簇索引，如果二级节点索引叶子结点中保存了行的所有需要查询的数据，那么就避免了二次查询的消耗；

**索引中满足查询的成本一般比查询行要小的多；**

explan 中 extra 列看到 using index 信息的时候，就叫做覆盖索引查询

![image](file://C:\Users%E5%87%A1%E6%98%AF%E5%85%AD%E4%B8%80\AppData\Roaming\Typora\typora-user-images\image-20230216211332261.png?lastModify=1692092896)

![image](file://C:\Users%E5%87%A1%E6%98%AF%E5%85%AD%E4%B8%80\AppData\Roaming\Typora\typora-user-images\image-20230216212236029.png?lastModify=1692092896)

- 无法使用覆盖查询，因为虽然覆盖了 where 查询，但是索引没有覆盖查询的所有列，
- MySQL 中不能再索引中执行 like 操作，虽然能够匹配最左原则，但是就是类似于‘xx%’这种可以操作，但是不可以使用‘%xx%’操作，如果是通配符开头的 Like 操作，存储引擎就无法做比较匹配；这种情况下只能提取数据行的值匹配，而不是通过索引值来查询；

**延迟关联**：

我们将索引扩展为某些特定字符，然后将查询到的某一列字段和表再次关联查询，得到数据值；

![image](file://C:\Users%E5%87%A1%E6%98%AF%E5%85%AD%E4%B8%80\AppData\Roaming\Typora\typora-user-images\image-20230217092243969.png?lastModify=1692092896)

- 这样的查询对于 actor 条件无法筛选的，查询速度比直接关联查询快，也就是 actor 的条件无法精确需要数据的，必须添加 title 作为辅助列的，这样的查询速度快，反之，则直接查询效率更高；

我们也可以使用聚簇索引中二级索引存储了叶子结点的主键值来通过主键值+索引列的方式，加快查询速度

![image](file://C:\Users%E5%87%A1%E6%98%AF%E5%85%AD%E4%B8%80\AppData\Roaming\Typora\typora-user-images\image-20230217092701356.png?lastModify=1692092896)

图中， last_name 作为索引列，actor_id 作为主键值,构成了覆盖索引的方式；

---

![image](file://C:\Users%E5%87%A1%E6%98%AF%E5%85%AD%E4%B8%80\AppData\Roaming\Typora\typora-user-images\image-20230217093353748.png?lastModify=1692092896)

所谓的延迟索引推送 ICP，就是将原本推送到存储引擎层的数据再进行一次过滤，改变了需要存储引擎层在进行一次过滤的需求；

```Plain Text
SELECT * FROM people
  WHERE zipcode='95054'
  AND lastname LIKE '%etrunia%'
  AND address LIKE '%Main Street%';
```

5.6 版本之前，对于这类引用，我们无法使用索引覆盖，因为\*表示查询所有字段，我们的索引没有覆盖到全部字段；这个 sql 语句的流程如下：

1. 查找匹配的索引元祖，类似于（95054,1）1 是主键
2. **通过 innodb 二次查找主键索引，然后拿出 1 列的证行数据，**
3. **服务器对于整行应用进行 where lastname LIKE '%etrunia%' AND address LIKE '%Main Street%' 条件判断，为 true 的时候，添加到结果集中；**

而 ICP 技术，就是将推送到服务器层的数据，存储引擎先进行过滤，然后满足条件的推送到服务器层中，这样减少了 IO 操作；等于就是将 23 合并到存储引擎层执行了，满足条件的推送到服务器层即可；

---

### 007 使用索引扫描来排序

当索引扫描不能覆盖查询的所有列的时候，本来比较快的索引扫描每次都需要扫描到一条记录，就进行一次回表查询操作，查询到整行记录，这些随机 I/O 比较影响性能，通常**，索引扫描的速度比顺序全表扫描慢；**

mysql 进行排序操作的时候，order by 后面的条件顺序，应该和索引顺序一致，否则需要执行排序操作，而无法利用索引排序；或者满足最左原则；

🍊 特殊：不满足最左前缀的情况就是前导列为常量的时候；

![image](file://C:\Users%E5%87%A1%E6%98%AF%E5%85%AD%E4%B8%80\AppData\Roaming\Typora\typora-user-images\image-20230217095636362.png?lastModify=1692092896)

使用 rental_date 是因为 rental_date 是常量，所以使用这个索引是可以的；

- 当 rental_date 是范围条件值的时候，无法使用索引，只能走排序；

```Plain Text
where rental_date > '023/02/17' order by inventory_id,customer_id;

## 或者类似这种，都无法使用范围查询
where rental_date = '023/02/17' and inventory_id in （1,2）, order by customer_id;
```

### 008 压缩前缀索引技术

所谓的压缩索引，就是将字符串进行压缩，以便于更多的在内存中存放数据，先完全保存第一个值，然后将其他值与第一个值作比较，将相同的部分存储字节数，不同的部分继续存储起来，起到压缩的方式；

比如第一个是 perform 我们先在 A1 存入 perform 第二个值是 performer 我们比较存入索引中的就是（7，rm）这样，就可以压缩索引；

压缩索引对于 I/O 密集型的查询速度快；但是对于某些操作查询比较慢，比如倒叙查询这种无法使用二分法查找的方式；

### 009 冗余和重复索引；

```Plain Text
create table test(
    id int not null primary key,
    a int not null,
    index(id,a)
    unique(id),
    index(id),

);

## 这种就是重复索引， primary key 就是索引，而且是唯一的；

# index(id,a) 这种就叫冗余索引，因为最左原则，如果创建了id，a 又创建了id这样就不符合最左原则；
```

### 010 未使用索引

通过 Percona Server 或者 mairaDB 打开 userstates 服务器变量，然后让服务器正常运行一段时间，再通过查询 information_schema.index.statistics 就可以查询到每个索引使用的频率；

### 011 索引和锁；

索引可以让查询锁定更少的行，一方面，行锁的额外开销大，另一方面，锁定不需要的行会增加锁争用并减少并发性；

InnoDB 在访问行的时候会增加行级锁，索引会减少 InnoDB 访问的行数，从而减少锁的数量；当索引无法过滤的时候，只能到服务器层才能使用 where 语句后面的条件筛选到无效的行，MySQL InnoDB 可以在服务器端过滤掉行后就释放锁；

InnoDB 在二级索引上使用共享读锁，但是访问主键索引需要排他写锁，这消除了使用覆盖索引的可能性；😢

并且 select for update 比 lock in share mode 或者非锁定查询要慢的多；

## 04 索引案例学习

我们如果新建索引，第一件事就是需要考虑使用索引进行排序还是使用检索数据在排序的方式；如果使用某个索引进行范围查询，那么就无法使用另外一个索引进行排序了；

### 001 支持多种过滤条件；

MD 我们索引选的的时候，选了两个索引选择性低的，但是可以使用范围的方式绕过这个，这样做法第一个就是使用这个做选择的时候可以使用最左匹配原则，第二就是如果没有使用到这个列，我们可以通过全选范围的方式绕过这个限定；比如 key(sex,country)这样的索引，我们如果没有用到 sex 的时候，我们也可以使用 sex in ('m','f')的方式绕开；

**基本原则：**

1. 考虑表上的所有选项；
2. 尽可能的重用索引而不是建立大量的组合索引；
3. 将预计使用到范围索引的查询放到最后；比如 age 这个多半就是范围查询；所以一般放到最后；
4. 使用 In 也不能太过于滥用，in 的范围是指数形式的增加的，多个 in 可能极大的降低性能；

### 002 避免多个范围条件

![image](file://C:\Users%E5%87%A1%E6%98%AF%E5%85%AD%E4%B8%80\AppData\Roaming\Typora\typora-user-images\image-20230217143422143.png?lastModify=1692092896)

如果上面那种情况，我们刻意视作范围查询，因为 type 是 range,但是下面的应该是等值查询，启用了 range 查询，就会导致索引失效的问题；范围查询会导致索引失效，等值查询可以使用索引；

```Plain Text
where last_online > date(now()) and age > 25;
```

对于这种情况，我们只能使用 last_online 索引或者 age 索引（需要调换位置）但是无法同时使用两个索引，如果使用到索引，只能通过其他的方式，比如维护一张登录表，在这张表中做等值查询。才可以；

### 003 优化查询

我们可以通过延迟关联的方式，使用这种方式，关联到所需要的行，减少需要扫描的行数；

```Plain Text
## 这里我们采用了key(sex,rating)的索引查询方式，使用覆盖查询。在二级索引查询到主键，然后通过主键过滤，这样就取消了需要筛选的行；
select col from profiles inner join
(select <primary key cols> from profiles where x.sex='M' order by rating limit 1000,10) x using (<primary key cols>)
```

## 05 维护索引和表

### 001 找到并修复损坏的表

```Plain Text
CHEAK TABLE 检查表是否损坏；

REPAIR TABLE 修复损坏的表；
## 如果碰到表存储引擎不支持REPAIR TABLE命令的， 可以修改表存储引擎；
alter table innodb_tb1 ENGLINE = INNODB;
```

### 002 更新索引统计信息

#### ANALYZE TABLE

1. 作用：分析指定表中的键值，并记录分布情况；
2. 限制，执行语句需要有 SELECT DELETE 权限，且只对存储引擎为 InnoDB、MyISAM、NDB 的表有作用，不能用于视图

| 列       | 解释                                    |
| -------- | --------------------------------------- |
| Table    | 表名                                    |
| Op       | 总是 analyze                            |
| Msg_type | status, error, info, note, 或者 warning |
| Msg_text | 信息                                    |

![image](file://C:\Users%E5%87%A1%E6%98%AF%E5%85%AD%E4%B8%80\AppData\Roaming\Typora\typora-user-images\image-20230217152401125.png?lastModify=1692092896)

4. ALALYZE TABLE 操作会将指定表从定义缓存中移除，并且对表加上读锁，排他锁，直到释放该锁的时候，才会被其它用户持有；mysql 会将 analize table 语句写入到 binlog 中，当服务同步数据的时候，以便能够同步；主从架构服务通过 binlog 与主服务完成数据同步；
5. 取消写入到 mysql

```Plain Text
analyze no_write_to_binlog table film;## 不写入语句到binlog中，
```

6. 分析步骤：
7. 我们通过分析 anylyze table 可以查询到表是否有问题；
8. 通过 show index 看索引的分布情况；

- cardinality （索引列的基数） 的值越接近于表总个数，那么索引越先被选择使用，差额越大，则被使用的概率越小；

![image](file://C:\Users%E5%87%A1%E6%98%AF%E5%85%AD%E4%B8%80\AppData\Roaming\Typora\typora-user-images\image-20230217153621992.png?lastModify=1692092896)

当使用到优秀索引的时候，Key 会展示索引；

![image](images/YqmwrjFxHtWy11kiV_fboo-I0iX85SzHmERyenc-Nn8.png)

当 cardinality 的值与表中的数据差距太大的时候，可能不会使用索引；

![image](images/xGtyLLEhsARFUrou8htVOwLFpQM_Bfwxl8jLhdKcACk.png)

7. 当表的大小发生了非常大的变化的，大小超过 1/16 或者新插入了 20 亿条数据，都会计算索引的统计信息；
8. 执行 anylize table 的时候由于会读锁，所以会影响性能，因为大量的锁争用问题会导致服务器额外压力，所以我们可以关闭写入操作，使用 innodb_status_on_metadata 操作避免问题了；

### 003 减少索引和数据的碎片

碎片分配：

1. 行碎片；

数据行被存储在多个地方的片段中，查询从索引中访问一行记录，行碎片会导致性能下降；

InnoDB 对于行碎片，会将缩小的行重写到一个片段中；所以不会产生，而 MyISAM 则会产生；

2. 行间碎片；

逻辑上顺序的页，或者行在磁盘上不是顺序存储的；

行间碎片对于全表扫描或者聚簇索引扫描操作会有很大影响，这些操作原本能从磁盘中按照顺序存储的数据中拿到合适数据，现在分成一段一段了；

3. 剩余空间碎片；

数据页中有大量的空余空间，浪费数据；

做法：

使用 OPTIMIZE TALBE 的方式整理数据

```Plain Text
## 整理表格；
OPTIMIZE  table <TABLENAME>;

## 如果不支持可以将引擎换为支持的存储引擎
alter table <table.name> engine = 'innodb'；# 这种方式就行；
```

## 06 总结

- 单行访问从数据块中只为了获取一行，这比较浪费资源；
- 顺序访问很快，1.顺序 I/O 不需要多次磁盘寻道，比随机 I/O 快的多，2.如果服务器能够按需要顺序读取数据，就不需要额外的排序操作；并且 group by 查询也无需再做排序和将行按组进行聚合查询了；
- 索引查询很快的原因是索引覆盖查询查到了所有的列，就不需要通过回表查找行的其他信息；避免了大量的行访问；

> 张晓凡 2023/8/16 上午 8:47:27

键前缀查找只适用于最左前缀的查找
